{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 建立和训练模型 #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$f('真好吃')=1$$\n",
    "$$f('太难吃')=0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**简介**\n",
    "在已有的多种类的合成语料库的基础上，我们想训练一个可以预测语言情感的模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import jieba # 结巴分词\n",
    "# gensim用来加载预训练word vector\n",
    "from gensim.models import KeyedVectors\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**预训练词向量**  \n",
    "我们使用了北京师范大学中文信息处理研究所与中国人民大学 DBIIR 实验室的研究者开源的\"chinese-word-vectors\" github链接为：  \n",
    "https://github.com/Embedding/Chinese-Word-Vectors  \n",
    "我们选用其中的Zhihu_QA Word + Character + Ngram模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用gensim加载预训练中文分词embedding\n",
    "cn_model = KeyedVectors.load_word2vec_format('./sgns.zhihu.bigram-char', \n",
    "                                          binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这个词向量模型里，每一个词是一个索引，对应的是一个长度为300的向量，我们今天构建的LSTM模型并不能直接处理汉字文本，需要先进行分次并把词汇转换为词向量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "词向量的长度为300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 6.10010e-02,  3.73003e-01, -2.71264e-01, -4.35535e-01,\n",
       "       -6.01495e-01, -5.51020e-02,  2.70148e-01,  2.28470e-02,\n",
       "        4.34196e-01,  1.59000e-02,  3.88832e-01,  3.25449e-01,\n",
       "        3.55190e-01, -1.42635e-01,  2.43506e-01,  8.29120e-02,\n",
       "        1.18370e-02,  5.00260e-01, -5.75470e-02,  1.35006e-01,\n",
       "        6.13185e-01,  2.80526e-01,  1.72192e-01,  4.25960e-02,\n",
       "       -1.32544e-01, -4.49176e-01, -6.74890e-02, -1.42176e-01,\n",
       "       -7.92340e-02, -2.94032e-01, -2.34870e-01, -3.96320e-02,\n",
       "       -1.49573e-01, -5.21620e-02,  5.70000e-04, -5.67600e-01,\n",
       "        3.01528e-01,  2.15771e-01, -5.68168e-01,  3.69633e-01,\n",
       "        2.38178e-01, -5.88849e-01,  9.80510e-02, -5.74732e-01,\n",
       "        9.97770e-02,  5.06527e-01, -6.89000e-04,  1.12211e-01,\n",
       "        4.56189e-01,  5.30550e-02, -3.90589e-01, -1.39010e-01,\n",
       "       -1.20160e-02,  1.39989e-01,  2.07110e-01,  1.05418e-01,\n",
       "       -5.12526e-01,  4.84178e-01, -4.09640e-02,  5.67858e-01,\n",
       "        1.46660e-01,  6.70660e-02, -1.70841e-01, -6.49581e-01,\n",
       "        4.08690e-02,  1.12702e-01, -1.06709e-01, -9.38010e-02,\n",
       "        2.32184e-01, -4.07022e-01, -1.85026e-01,  2.86670e-01,\n",
       "       -3.14916e-01, -2.10623e-01,  2.63242e-01,  2.62617e-01,\n",
       "        2.66353e-01, -4.73998e-01,  5.21712e-01,  5.66260e-02,\n",
       "       -2.08403e-01, -1.53613e-01, -3.70159e-01,  2.48781e-01,\n",
       "        1.77609e-01, -5.55530e-01, -6.98920e-02, -1.49933e-01,\n",
       "        3.96214e-01, -5.53600e-03,  7.30410e-01,  8.83740e-02,\n",
       "       -2.40953e-01, -3.21611e-01,  3.05782e-01, -3.22295e-01,\n",
       "       -2.03990e-02, -1.50269e-01,  4.52150e-01,  2.65968e-01,\n",
       "       -1.53943e-01,  4.89851e-01,  1.58508e-01, -7.72040e-02,\n",
       "       -1.38264e-01,  1.79352e-01,  5.91109e-01, -1.93515e-01,\n",
       "       -2.65414e-01,  2.91690e-02, -2.42270e-02, -1.13297e-01,\n",
       "       -2.51131e-01, -2.98754e-01, -3.60400e-01,  6.18520e-01,\n",
       "        1.43720e-01,  3.36966e-01,  2.24260e-01, -2.02762e-01,\n",
       "       -4.17160e-01, -6.86869e-01, -4.62429e-01, -4.48345e-01,\n",
       "       -1.59600e-02, -5.07098e-01,  4.12422e-01, -2.46990e-02,\n",
       "        1.82142e-01,  8.60700e-03, -2.88007e-01, -1.54406e-01,\n",
       "        4.53406e-01, -4.74606e-01, -6.06370e-02,  2.13933e-01,\n",
       "        2.13533e-01, -1.84520e-02,  1.23745e-01, -5.36700e-02,\n",
       "       -7.21376e-01,  1.04269e-01, -1.77379e-01, -3.60725e-01,\n",
       "       -3.14810e-02, -6.65600e-03,  8.88600e-03,  3.50413e-01,\n",
       "        3.26199e-01,  1.17418e-01, -3.17388e-01, -1.48197e-01,\n",
       "       -1.06230e-02,  5.91898e-01,  1.20318e-01, -3.04638e-01,\n",
       "        1.11694e-01, -2.64055e-01, -5.23850e-02, -8.19080e-02,\n",
       "       -1.15543e-01,  3.16133e-01, -6.62567e-01, -8.74590e-02,\n",
       "        4.00417e-01, -2.99562e-01, -3.35561e-01, -3.82670e-02,\n",
       "        1.12876e-01,  5.52232e-01,  2.96045e-01, -2.93569e-01,\n",
       "       -5.91591e-01,  3.30521e-01, -3.00754e-01,  2.84500e-02,\n",
       "        6.45168e-01,  1.53424e-01, -6.74950e-02,  8.34670e-02,\n",
       "       -2.24183e-01, -1.28901e-01, -1.41547e-01,  3.65555e-01,\n",
       "        8.97839e-01, -5.04058e-01,  3.33932e-01, -2.70164e-01,\n",
       "        1.76177e-01,  9.86480e-02,  2.93401e-01,  1.22525e-01,\n",
       "       -8.00475e-01,  5.71464e-01,  2.34868e-01,  5.39504e-01,\n",
       "       -7.99310e-02, -1.07765e-01, -4.40381e-01, -2.18147e-01,\n",
       "        3.31430e-02, -2.00942e-01,  8.18490e-02,  6.39455e-01,\n",
       "        8.43210e-02, -4.55040e-02, -2.80520e-02,  1.44280e-01,\n",
       "        1.97674e-01, -5.59610e-02,  3.08692e-01,  5.98595e-01,\n",
       "       -5.90669e-01, -8.65100e-03,  1.84820e-01, -2.45560e-02,\n",
       "       -2.02455e-01,  5.42187e-01,  5.00321e-01,  5.69280e-01,\n",
       "        2.46618e-01, -4.85250e-02,  2.84700e-02,  1.50363e-01,\n",
       "        2.80797e-01,  7.68630e-02, -5.08052e-01, -2.84150e-02,\n",
       "        4.50810e-02,  1.91678e-01,  6.17870e-02, -1.05636e-01,\n",
       "       -9.01020e-02, -2.13954e-01, -2.92664e-01,  4.30680e-02,\n",
       "        1.96947e-01,  3.80680e-02, -2.25015e-01, -4.25964e-01,\n",
       "       -1.88292e-01,  9.47030e-02,  2.58970e-02,  9.16900e-03,\n",
       "       -3.38122e-01,  3.44274e-01,  3.69085e-01, -8.23600e-02,\n",
       "        6.99804e-01,  5.86280e-02,  3.04001e-01, -2.80311e-01,\n",
       "       -4.62449e-01,  3.59410e-01, -4.66835e-01,  3.83574e-01,\n",
       "        9.88710e-02,  4.17252e-01, -1.63432e-01, -3.27480e-02,\n",
       "       -9.30360e-02,  6.43980e-02,  4.10505e-01, -1.37565e-01,\n",
       "        9.88840e-02, -1.34465e-01, -2.88367e-01,  5.96274e-01,\n",
       "        2.40831e-01,  9.09090e-02, -2.55965e-01, -2.27164e-01,\n",
       "        8.41010e-02, -5.10205e-01, -4.66066e-01,  2.56819e-01,\n",
       "       -2.31863e-01,  8.40051e-01, -5.84330e-01,  2.27812e-01,\n",
       "       -2.87118e-01,  2.74770e-01, -1.40350e-02,  1.25445e-01,\n",
       "        6.02468e-01,  7.58130e-02, -3.92958e-01,  1.58440e-01,\n",
       "        2.16795e-01, -3.06450e-02, -2.82605e-01,  3.00421e-01,\n",
       "       -6.51150e-02,  5.70766e-01,  1.56635e-01, -1.63628e-01,\n",
       "        1.07078e-01, -2.37947e-01,  5.86520e-02, -1.96095e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 由此可见每一个词都对应一个长度为300的向量\n",
    "embedding_dim = cn_model['南方科技大学'].shape[0]\n",
    "print('词向量的长度为{}'.format(embedding_dim))\n",
    "cn_model['南方科技大学']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有了词向量模型，我们可以轻松地寻找近义词、同类词。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7151298"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算相似度\n",
    "cn_model.similarity('橘子', '橙子')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('本科', 0.6586681604385376),\n",
       " ('大学本科', 0.6412541270256042),\n",
       " ('大学毕业', 0.6330900192260742),\n",
       " ('高中', 0.6304237246513367),\n",
       " ('师范大学', 0.620072066783905),\n",
       " ('中学', 0.6154141426086426),\n",
       " ('读研', 0.5873822569847107),\n",
       " ('研究生', 0.5832617282867432),\n",
       " ('宾大', 0.5808302760124207),\n",
       " ('军校', 0.5738762021064758)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 找出最相近的词，余弦相似度\n",
    "cn_model.most_similar(positive=['大学'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在 老师 会计师 程序员 律师 医生 老人 中:\n",
      "不是同一类别的词为: 老人\n"
     ]
    }
   ],
   "source": [
    "# 找出不同的词\n",
    "test_words = '老师 会计师 程序员 律师 医生 老人'\n",
    "test_words_result = cn_model.doesnt_match(test_words.split())\n",
    "print('在 '+test_words+' 中:\\n不是同一类别的词为: %s' %test_words_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Neg_data_ed.txt\n"
     ]
    },
    {
     "ename": "UnsupportedOperation",
     "evalue": "not readable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnsupportedOperation\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [19], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m txt \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(path \u001b[39m+\u001b[39m Cat_Data[i] \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m.txt\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39ma\u001b[39m\u001b[39m'\u001b[39m, encoding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m----> 9\u001b[0m     line \u001b[39m=\u001b[39m txt\u001b[39m.\u001b[39;49mread(\u001b[39m1048\u001b[39;49m)\n\u001b[0;32m     10\u001b[0m     \u001b[39mprint\u001b[39m(line,end\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     11\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m line:\n",
      "\u001b[1;31mUnsupportedOperation\u001b[0m: not readable"
     ]
    }
   ],
   "source": [
    "Cat_Data = ['Neg_data_ed','Pos_data_ed']\n",
    "path = './'\n",
    "data_recorder = []\n",
    "\n",
    "for i in range(2):\n",
    "    print(path + Cat_Data[i] + '.txt')\n",
    "    txt = open(path + Cat_Data[i] + '.txt', 'r', encoding='utf-8')\n",
    "    while True:\n",
    "        line = txt.read(1048)\n",
    "        print(line,end=\"\")\n",
    "        if not line:\n",
    "            break\n",
    "    txt.close\n",
    "    #data = txt.read().split('/n')\n",
    "    #data_recorder.append([data,i])\n",
    "print(data_recorder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f3041bd533004b2254ccb1f4db718601acc46e038d61812d0cb61175780c7b56"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
